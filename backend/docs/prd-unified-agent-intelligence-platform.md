# Product Requirements Document: Unified Agent Intelligence Platform (UAIP)

**Version**: 1.0  
**Date**: December 2024  
**Status**: In Development - Phase 1 Complete  
**Document Owner**: Product Team  
**Engineering Lead**: TBD  
**Security Lead**: TBD  

---

## 1. Executive Summary

### 1.1 Vision Statement
Transform Council of Nycea agents from conversational participants into autonomous intelligent actors that seamlessly combine external tool usage with artifact generation, creating a unified experience where agents can analyze situations, execute actions, and deliver concrete results.

### 1.2 Mission
Enable teams to achieve 10x productivity by providing AI agents that can independently complete end-to-end workflows‚Äîfrom analysis and planning to execution and delivery‚Äîwhile maintaining security, transparency, and user control.

### 1.3 Strategic Context
- **Current State**: Agents participate in conversations but cannot take concrete actions
- **Problem**: Users must manually bridge the gap between discussion and execution
- **Opportunity**: Create the first truly autonomous agentic workspace platform
- **Market Position**: Pioneer in enterprise agentic AI platforms

---

## 2. Current Development Status

### 2.1 Backend Implementation Progress

**Overall Status**: Phase 1 Foundation Complete (‚úÖ), Phase 2 Integration In Progress (üîÑ)

#### Completed Components (‚úÖ)

**Infrastructure & DevOps**:
- ‚úÖ Docker Compose configuration with full service orchestration
- ‚úÖ Multi-database setup (PostgreSQL, Neo4j, Redis, Qdrant, RabbitMQ)
- ‚úÖ Monorepo structure with TypeScript project references
- ‚úÖ Shared configuration and TypeScript support for UAIP backend
- ‚úÖ Health monitoring and service dependency management

**Core Services Architecture**:
- ‚úÖ **Agent Intelligence Service** - Context analysis and decision making engine
- ‚úÖ **Capability Registry Service** - Unified registry of tools and artifact templates  
- ‚úÖ **Orchestration Pipeline Service** - Asynchronous execution pipeline
- ‚úÖ **Security Gateway Service** - Authentication and authorization framework

**Shared Components**:
- ‚úÖ Shared types and interfaces (72+ TypeScript files)
- ‚úÖ Common middleware and utilities
- ‚úÖ Error handling and logging framework
- ‚úÖ Database services and configuration management

**Development Infrastructure**:
- ‚úÖ TypeScript monorepo with proper workspace configuration
- ‚úÖ Build and development scripts
- ‚úÖ Testing framework setup
- ‚úÖ API testing and validation scripts

#### In Progress Components (üîÑ)

**Service Implementation**:
- üîÑ Agent Intelligence Engine core algorithms
- üîÑ Tool-artifact coordination workflows
- üîÑ Security approval workflows
- üîÑ Real-time operation monitoring

**Integration Layer**:
- üîÑ MCP server integration
- üîÑ WebSocket real-time communication
- üîÑ Inter-service communication protocols

#### Pending Components (‚è≥)

**Advanced Features**:
- ‚è≥ Machine learning decision optimization
- ‚è≥ Performance analytics and insights
- ‚è≥ Advanced security policies
- ‚è≥ Production deployment automation

### 2.2 Git Commit History Analysis

**Recent Development Activity** (Last 10 commits):
1. `a563e87` - Docker Compose configuration and initial backend setup
2. `9ff37f8` - Capability Registry service with core functionality  
3. `9d2910c` - Agent Intelligence service with Docker support
4. `0076c57` - Shared configuration and TypeScript support for UAIP backend
5. `d79e7c3` - Shared middleware implementation for UAIP backend
6. `47a7cdf` - Shared services implementation for UAIP backend
7. `57d85d8` - Shared types and utilities for UAIP services
8. `f36fea8` - Error handling utilities and logging framework

**Development Velocity**: 8 major commits in recent development cycle, indicating active development phase.

**Code Metrics**:
- **Backend Services**: 32 TypeScript files implemented
- **Shared Components**: 72 TypeScript files implemented  
- **Total Backend Codebase**: 104+ TypeScript files
- **Service Coverage**: 4/4 core services scaffolded and partially implemented

### 2.3 Architecture Validation

**‚úÖ Confirmed Architecture Decisions**:
- Monorepo structure with workspace-based imports
- TypeScript project references for build optimization
- Docker-based development and deployment
- Multi-database architecture for different data types
- Microservices architecture with shared components

**üîÑ Implementation Gaps Identified**:
- Frontend integration layer not yet started
- Real-time WebSocket communication needs implementation
- Security approval workflows need completion
- Performance monitoring and analytics pending

---

## 3. Problem Statement

### 3.1 User Pain Points

#### For Developers:
- **Context Switching**: Must switch between chat and tools to get work done
- **Manual Translation**: Must convert agent suggestions into actionable code/configs
- **Tool Fragmentation**: Different interfaces for different capabilities
- **Slow Iteration**: Agents can discuss but can't implement or test solutions

#### For Product Managers:
- **Documentation Lag**: Decisions made in chat don't automatically become documented requirements
- **Manual Synthesis**: Must manually compile discussion insights into PRDs/specs
- **Status Tracking**: No visibility into what agents are actually capable of doing

#### For DevOps Teams:
- **Deployment Friction**: Agents can suggest infrastructure changes but can't implement them
- **Monitoring Gaps**: No integration between agent insights and operational actions
- **Approval Bottlenecks**: Manual handoffs for security-sensitive operations

### 3.2 Business Impact
- **Reduced Productivity**: Teams spend 40% of time on manual translation of decisions to actions
- **Delayed Delivery**: Average 2-3 day delay between decision and implementation
- **Inconsistent Quality**: Manual processes lead to errors and omissions
- **Limited Adoption**: Current agents viewed as "nice to have" rather than essential tools

---

## 4. Target Users & Personas

### 4.1 Primary Personas

#### Persona 1: Senior Developer (Alex)
- **Role**: Senior Software Engineer, Tech Lead
- **Goals**: Fast implementation, high code quality, automated workflows
- **Pain Points**: Context switching, manual code reviews, deployment coordination
- **Success Metrics**: Code commits per week, bug reduction, deployment frequency

#### Persona 2: Product Manager (Sarah)
- **Role**: Senior Product Manager
- **Goals**: Clear requirements, stakeholder alignment, delivery tracking
- **Pain Points**: Manual documentation, requirement drift, status visibility
- **Success Metrics**: Feature delivery time, requirement clarity, stakeholder satisfaction

#### Persona 3: DevOps Engineer (Raj)
- **Role**: Platform Engineer, SRE
- **Goals**: Reliable deployments, infrastructure automation, security compliance
- **Pain Points**: Manual deployments, security review bottlenecks, monitoring gaps
- **Success Metrics**: Deployment success rate, MTTR, security compliance scores

### 4.2 Secondary Personas
- **Junior Developers**: Need guided assistance and learning
- **QA Engineers**: Require test generation and validation automation
- **Security Engineers**: Need audit trails and compliance reporting
- **Engineering Managers**: Want productivity insights and team optimization

---

## 5. Solution Overview

### 5.1 Core Concept
**"One Conversation, Infinite Capabilities"** - Users interact with agents through natural conversation, while agents intelligently coordinate tool usage and artifact generation behind the scenes.

### 5.2 Key Capabilities

#### 5.2.1 Intelligent Action Planning
Agents analyze conversation context and automatically determine the optimal combination of:
- **Tool Usage**: External API calls, database queries, file operations
- **Artifact Generation**: Code, documentation, tests, configurations
- **Hybrid Workflows**: Tools inform artifact generation and vice versa

#### 5.2.2 Unified Execution Pipeline
Single asynchronous pipeline that handles:
- Tool execution (seconds timeframe)
- Artifact generation (minutes timeframe) 
- DevOps operations (hours timeframe)
- Approval workflows for restricted operations

#### 5.2.3 Progressive Disclosure Interface
Layered UI that scales from simple chat to detailed operation monitoring:
- **Level 1**: Natural conversation with progress indicators
- **Level 2**: Operation status cards with expandable details
- **Level 3**: Full execution logs, metrics, and debugging information

#### 5.2.4 Security Orchestration
Unified security model covering:
- Agent capability permissions
- Resource access controls
- Operation approval workflows
- Complete audit trails

---

## 6. User Stories & Acceptance Criteria

### 6.1 Epic 1: Intelligent Action Planning

#### Story 1.1: Automatic Capability Detection
**As a developer**, I want agents to automatically determine whether my request needs tool usage, artifact generation, or both, so I don't have to specify implementation details.

**Acceptance Criteria:**
- [ ] Agent analyzes conversation context with 95% accuracy
- [ ] Agent explains planned actions before execution
- [ ] User can approve/modify agent's action plan
- [ ] Agent adapts plan based on user feedback

#### Story 1.2: Context-Aware Decision Making
**As a user**, I want agents to consider previous conversation history and available resources when planning actions, so recommendations are relevant and feasible.

**Acceptance Criteria:**
- [ ] Agent considers last 50 messages for context
- [ ] Agent checks available tools and permissions
- [ ] Agent provides rationale for chosen approach
- [ ] Agent suggests alternatives when primary approach isn't available

### 6.2 Epic 2: Unified Tool & Artifact Coordination

#### Story 2.1: Tool-Informed Artifact Generation
**As a developer**, I want agents to use tool results to enhance artifact generation (e.g., use git diff to inform code suggestions), so artifacts are more accurate and contextual.

**Acceptance Criteria:**
- [ ] Agent can chain tool execution with artifact generation
- [ ] Tool results are properly formatted for artifact templates
- [ ] Agent explains how tool results influenced artifact content
- [ ] Generated artifacts include traceability to source tools

#### Story 2.2: Artifact-Triggered Tool Usage
**As a DevOps engineer**, I want generated artifacts to automatically trigger relevant tools (e.g., deploy generated configurations), so the end-to-end workflow is seamless.

**Acceptance Criteria:**
- [ ] Agent can identify deployment-ready artifacts
- [ ] Agent suggests appropriate deployment tools/workflows
- [ ] User can approve automatic deployment pipeline
- [ ] Agent monitors deployment status and reports results

### 6.3 Epic 3: Progressive Disclosure Interface

#### Story 3.1: Simple Chat Experience
**As any user**, I want to interact with enhanced agents through normal conversation without needing to understand technical complexity, so adoption is frictionless.

**Acceptance Criteria:**
- [ ] Chat interface looks and feels like current agent conversations
- [ ] Operation progress shown with simple status indicators
- [ ] Technical details hidden by default but accessible
- [ ] Error messages are user-friendly with suggested actions

#### Story 3.2: Detailed Operation Monitoring
**As a power user**, I want to see detailed execution logs, performance metrics, and debugging information when needed, so I can understand and optimize agent behavior.

**Acceptance Criteria:**
- [ ] Expandable operation details panel
- [ ] Real-time execution logs with filtering
- [ ] Performance metrics and timing information
- [ ] Error details with stack traces and debugging context

### 6.4 Epic 4: Security & Approval Workflows

#### Story 4.1: Granular Permission Control
**As a security administrator**, I want to configure fine-grained permissions for what each agent can access and modify, so security policies are enforced consistently.

**Acceptance Criteria:**
- [ ] Role-based access control for agents and users
- [ ] Resource-level permissions (repositories, databases, APIs)
- [ ] Operation-level restrictions (read vs. write vs. deploy)
- [ ] Permission inheritance and delegation rules

#### Story 4.2: Streamlined Approval Process
**As a team lead**, I want a fast and intuitive approval process for high-risk operations, so security doesn't slow down legitimate work.

**Acceptance Criteria:**
- [ ] Context-rich approval requests with risk assessment
- [ ] One-click approve/reject with optional feedback
- [ ] Batch approval for related operations
- [ ] Escalation rules for time-sensitive approvals

---

## 7. Functional Requirements

### 7.1 Core System Requirements

#### 7.1.1 Agent Intelligence Engine
- **Requirement**: Analyze conversation context and determine optimal action strategy
- **Input**: Conversation history, user request, available capabilities
- **Output**: Action plan with tool/artifact recommendations and confidence scores
- **Performance**: 95% accuracy, <2s response time
- **Scale**: Support 1000 concurrent decision requests

#### 7.1.2 Capability Registry
- **Requirement**: Unified registry of tools and artifact generation templates
- **Features**: Dynamic registration, dependency management, version control
- **Integration**: Support for MCP servers and custom tool definitions
- **Performance**: <100ms lookup time, 99.9% availability
- **Scale**: Support 10,000 registered capabilities

#### 7.1.3 Execution Pipeline
- **Requirement**: Asynchronous execution of tools and artifact generation
- **Features**: Parallel execution, dependency resolution, state management
- **Reliability**: Retry logic, circuit breakers, graceful degradation
- **Performance**: Handle 10,000 concurrent operations
- **Monitoring**: Real-time status tracking and metrics collection

#### 7.1.4 Security Framework
- **Requirement**: Comprehensive security and access control
- **Features**: RBAC, resource permissions, approval workflows, audit logging
- **Compliance**: SOC2, GDPR compliance ready
- **Performance**: <50ms permission checks
- **Audit**: Complete tamper-proof audit trail

### 7.2 Integration Requirements

#### 7.2.1 MCP Server Integration
- **Support**: All existing MCP servers from implementation guide
- **Management**: Start/stop, health monitoring, automatic restart
- **Security**: Sandboxed execution, resource limits
- **Performance**: <1s tool execution for simple operations

#### 7.2.2 Artifact Generation Integration
- **Templates**: Code, documentation, tests, configurations
- **Quality**: Syntax validation, security scanning, best practice checking
- **Versioning**: Template versioning and rollback capability
- **Performance**: <30s for simple artifacts, <5min for complex artifacts

#### 7.2.3 DevOps Integration
- **VCS**: GitHub, GitLab, Bitbucket support
- **CI/CD**: GitHub Actions, Jenkins, CircleCI integration
- **Infrastructure**: Kubernetes, Docker, cloud providers
- **Monitoring**: Prometheus, Grafana, custom dashboards

---

## 8. Non-Functional Requirements

### 8.1 Performance Requirements
- **Response Time**: <2s for agent decisions, <5s for simple operations
- **Throughput**: 10,000 concurrent users, 100,000 operations/hour
- **Scalability**: Horizontal scaling to 50+ nodes
- **Availability**: 99.9% uptime SLA

### 8.2 Security Requirements
- **Authentication**: Multi-factor authentication required
- **Authorization**: Role-based access control with fine-grained permissions
- **Encryption**: Data encrypted at rest and in transit (AES-256, TLS 1.3)
- **Audit**: Complete audit trail with tamper-proof logging
- **Compliance**: SOC2 Type II, GDPR, HIPAA ready

### 8.3 Usability Requirements
- **Learning Curve**: New users productive within 30 minutes
- **Accessibility**: WCAG 2.1 AA compliance
- **Mobile**: Responsive design supporting tablet/mobile viewing
- **Internationalization**: Multi-language support for 5 major languages

### 8.4 Reliability Requirements
- **Fault Tolerance**: System continues operating with 20% component failure
- **Data Integrity**: Zero data loss, automatic backup and recovery
- **Disaster Recovery**: <4 hour RTO, <1 hour RPO
- **Monitoring**: Real-time health monitoring with automated alerting

---

## 9. Success Metrics & KPIs

### 9.1 User Experience Metrics
| Metric | Current | Target | Measurement |
|--------|---------|--------|-------------|
| Time to First Value | N/A | <5 minutes | User completes first successful agent workflow |
| User Satisfaction | N/A | 4.5/5.0 | Monthly NPS survey |
| Feature Adoption | N/A | 80% within 30 days | Users who try advanced features |
| Support Tickets | N/A | <5% of users | Users requiring help per month |

### 9.2 Productivity Metrics
| Metric | Current | Target | Measurement |
|--------|---------|--------|-------------|
| Development Velocity | Baseline | +50% | Story points delivered per sprint |
| Time to Deployment | Baseline | -60% | Commit to production time |
| Bug Reduction | Baseline | -40% | Production bugs per feature |
| Documentation Coverage | Baseline | +200% | Features with complete docs |

### 9.3 Technical Metrics
| Metric | Target | Measurement |
|--------|--------|-------------|
| System Uptime | 99.9% | Monthly availability |
| Response Time | <2s | 95th percentile API response time |
| Error Rate | <0.1% | Failed operations / total operations |
| Security Incidents | 0 | Monthly security audit |

### 9.4 Business Metrics
| Metric | Target | Measurement |
|--------|--------|-------------|
| Customer Retention | +15% | Annual renewal rate |
| Expansion Revenue | +25% | Upsell revenue from enhanced agents |
| Market Position | Top 3 | Industry analyst rankings |
| Competitive Wins | 70% | Win rate vs. competitors |

---

## 10. Risk Assessment & Mitigation

### 10.1 Technical Risks

#### Risk: System Complexity
- **Probability**: Medium
- **Impact**: High
- **Mitigation**: Modular architecture, comprehensive testing, phased rollout

#### Risk: Performance Degradation
- **Probability**: Medium
- **Impact**: Medium
- **Mitigation**: Load testing, performance monitoring, auto-scaling

#### Risk: Security Vulnerabilities
- **Probability**: Low
- **Impact**: Critical
- **Mitigation**: Security audits, penetration testing, bug bounty program

### 10.2 Product Risks

#### Risk: User Adoption Challenges
- **Probability**: Medium
- **Impact**: High
- **Mitigation**: User research, beta testing, comprehensive onboarding

#### Risk: Feature Creep
- **Probability**: High
- **Impact**: Medium
- **Mitigation**: Strict prioritization, MVP focus, regular reviews

#### Risk: Competitive Response
- **Probability**: High
- **Impact**: Medium
- **Mitigation**: Speed to market, patent protection, network effects

### 10.3 Business Risks

#### Risk: Resource Constraints
- **Probability**: Medium
- **Impact**: High
- **Mitigation**: Phased development, resource planning, contractor support

#### Risk: Market Timing
- **Probability**: Low
- **Impact**: High
- **Mitigation**: Market research, customer validation, flexible launch

---

## 11. Implementation Timeline

### 11.1 Development Phases

#### Phase 1: Foundation (Weeks 1-4) ‚úÖ COMPLETED
- **Goals**: Core architecture and basic integration
- **Deliverables**: 
  - ‚úÖ Agent Intelligence Engine (basic architecture)
  - ‚úÖ Unified Capability Registry (service implemented)
  - ‚úÖ Security Framework (core structure)
  - ‚úÖ Docker Compose infrastructure setup
  - ‚úÖ Monorepo TypeScript configuration
  - ‚úÖ Shared services and utilities (72+ files)
- **Success Criteria**: ‚úÖ Agents can make simple tool vs. artifact decisions
- **Actual Completion**: Phase 1 completed with comprehensive backend foundation

#### Phase 2: Integration (Weeks 5-8) üîÑ IN PROGRESS
- **Goals**: Tool-artifact coordination and approval workflows
- **Deliverables**:
  - üîÑ Execution Pipeline with state management
  - üîÑ Approval workflow system
  - üîÑ Enhanced monitoring and logging
  - ‚è≥ Progressive disclosure UI components (Frontend pending)
  - üîÑ MCP server integration
- **Success Criteria**: Complex hybrid workflows work end-to-end
- **Current Status**: Backend services 70% complete, Frontend integration needed

#### Phase 3: Intelligence (Weeks 9-12) ‚è≥ PLANNED
- **Goals**: Advanced decision-making and optimization
- **Deliverables**:
  - ‚è≥ Context-aware decision algorithms
  - ‚è≥ Learning and adaptation systems
  - ‚è≥ Advanced security policies
  - ‚è≥ Performance optimization
  - ‚è≥ Frontend progressive disclosure implementation
- **Success Criteria**: Agents demonstrate intelligent behavior adaptation
- **Dependencies**: Phase 2 completion, Frontend development start

#### Phase 4: Production (Weeks 13-16) ‚è≥ PLANNED
- **Goals**: Production readiness and scale testing
- **Deliverables**:
  - ‚è≥ Load testing and optimization
  - ‚è≥ Security audit and compliance
  - ‚è≥ Documentation and training
  - ‚è≥ Gradual rollout plan
  - ‚è≥ Frontend-backend integration testing
- **Success Criteria**: System ready for production deployment

### 11.2 Updated Milestone Schedule

| Milestone | Week | Description | Status | Exit Criteria |
|-----------|------|-------------|--------|---------------|
| Architecture Complete | 2 | Core system design finalized | ‚úÖ DONE | Technical review approved |
| Backend Foundation | 4 | Backend services scaffolded | ‚úÖ DONE | All 4 core services operational |
| Frontend Integration Start | 6 | Frontend development begins | üîÑ CURRENT | React app with UAIP integration |
| Alpha Release | 8 | Internal testing version | ‚è≥ NEXT | Basic workflows functional |
| Beta Release | 12 | Customer preview version | ‚è≥ PLANNED | User acceptance testing passed |
| RC Release | 15 | Release candidate | ‚è≥ PLANNED | Performance and security validated |
| GA Release | 16 | General availability | ‚è≥ PLANNED | Production deployment successful |

### 11.3 Immediate Next Steps (Current Sprint)

**Priority 1: Frontend Integration Foundation**
- [ ] Set up React/TypeScript frontend project
- [ ] Implement WebSocket communication layer
- [ ] Create basic UAIP dashboard components
- [ ] Integrate with existing backend APIs

**Priority 2: Backend Service Completion**
- [ ] Complete Agent Intelligence Engine core algorithms
- [ ] Implement real-time operation monitoring
- [ ] Finish security approval workflows
- [ ] Add comprehensive API documentation

**Priority 3: Integration Testing**
- [ ] End-to-end workflow testing
- [ ] Performance benchmarking
- [ ] Security penetration testing
- [ ] User acceptance testing preparation

---

## 12. Resource Requirements

### 12.1 Engineering Team
- **Backend Engineers**: 4 FTE (TypeScript/Node.js, distributed systems)
- **Frontend Engineers**: 3 FTE (React, TypeScript, complex UI/UX)
- **DevOps Engineers**: 2 FTE (Kubernetes, CI/CD, monitoring)
- **Security Engineers**: 1 FTE (application security, compliance)
- **QA Engineers**: 2 FTE (automation, integration testing)

### 12.2 Infrastructure
- **Development**: 8 cores, 32GB RAM, 1TB storage per environment
- **Staging**: 16 cores, 64GB RAM, 2TB storage
- **Production**: Auto-scaling 50-200 cores, 200-800GB RAM
- **Database**: PostgreSQL cluster with read replicas
- **Monitoring**: Prometheus, Grafana, ELK stack
- **Security**: WAF, SIEM, vulnerability scanning

### 12.3 External Dependencies
- **LLM Providers**: OpenAI GPT-4, Anthropic Claude, Google Gemini
- **VCS Providers**: GitHub Enterprise, GitLab, Bitbucket
- **CI/CD Platforms**: GitHub Actions, Jenkins, CircleCI
- **Monitoring Tools**: DataDog, New Relic, PagerDuty
- **Security Tools**: Vault, Okta, Snyk

---

## 13. Go-to-Market Strategy

### 13.1 Launch Strategy
- **Phase 1**: Internal dogfooding (Weeks 1-4)
- **Phase 2**: Closed beta with 10 enterprise customers (Weeks 5-8)
- **Phase 3**: Open beta with 100 customers (Weeks 9-12)
- **Phase 4**: General availability launch (Week 16)

### 13.2 Pricing Strategy
- **Enterprise Tier**: $50/user/month for enhanced agents
- **Premium Tier**: $100/user/month with advanced automation
- **Enterprise Plus**: Custom pricing for large deployments

### 13.3 Marketing Positioning
- **Primary Message**: "The first truly autonomous AI agents for enterprise teams"
- **Key Differentiators**: End-to-end automation, security-first design, proven at scale
- **Target Channels**: Developer conferences, enterprise sales, content marketing

---

## 14. Appendices

### 14.1 Glossary
- **Agent**: AI-powered assistant capable of conversation and action
- **Tool**: External capability accessible via API or command line
- **Artifact**: Generated deliverable (code, docs, configs)
- **MCP**: Model Context Protocol for tool integration
- **UAIP**: Unified Agent Intelligence Platform

### 14.2 References
- Epic 3: Agent Tooling and Automation Implementation Guide
- Epic 4: Artifact Generation and DevOps Integration
- Council of Nycea Architecture Documentation
- Security and Compliance Requirements

### 14.3 Decision Log
| Date | Decision | Rationale | Owner |
|------|----------|-----------|--------|
| 2024-12 | Unified architecture over microservices | Simpler development and deployment | Tech Lead |
| 2024-12 | Progressive disclosure UI approach | Balance simplicity with power user needs | UX Lead |
| 2024-12 | Security-first integration model | Enterprise requirements mandate robust security | Security Lead |

---

**Document Status**: Draft for Review  
**Next Review Date**: [To be scheduled]  
**Stakeholder Sign-off**: [ ] Product [ ] Engineering [ ] Security [ ] Leadership 